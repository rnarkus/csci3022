{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: Markus Hudobnik\n",
    "\n",
    "**Section**: 002\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday September 15th**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.   \n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Unless a url is given for a data set, you will find the required data in the same directory as this assignment on GitHub.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Piazza on writing math in Markdown. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "***\n",
    "\n",
    "An owner of a taxi company wants to estimate his fleet's average fuel economy over the next year in order to estimate the company's future fuel costs.  His fleet of taxis is made up of 100 Crown Victorias, 50 Toyota Priuses, and 50 Ford Escapes.  The owner randomly selects 12 vehicles from his vehicle registration rolls and tracks their fuel usage in miles per gallon over the next week.  So as to get a proper estimate, he intentionally selects 6 Crown Vics, 3 Priuses, and 3 Escapes to track. \n",
    "\n",
    "Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Population:** The Taxi company's fleet  \n",
    "**Sample Frame:** 12 vehicles  \n",
    "**Sample:** 6 Crown Vics, 3 Priuses, and 3 Escapes  \n",
    "**Type of Sample:** Stratified sample  \n",
    "- Proportionate sample to the overall population. Since we had 100 Crown Vics, 50 Priuses and 50 escapes, out of the sample frame of 12 vehicles, 6 would be Crown Vics, 3 priuses, and 3 escapes.  \n",
    " \n",
    "**Quantity of Interest:** future fuel costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 \n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and the sample median to extreme outliers is to replace one or more elements in a given dataset by a number $y$ and investigate the eﬀect when $y$ goes to inﬁnity. To illustrate this, consider the dataset\n",
    "\n",
    "$$\n",
    "4.6 \\quad \n",
    "3.0 \\quad \n",
    "3.2 \\quad\n",
    "4.2 \\quad\n",
    "5.0\n",
    "$$\n",
    "\n",
    "with sample mean $4$ and sample median $4.2$. \n",
    "\n",
    "**Part A**: We replace the element $3.2$ by some real number $y$. What happens with the sample mean and the sample median of this new dataset as $y \\rightarrow \\infty$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   4.2  4.6  5.   7. ]\n",
      "4.76\n",
      "4.6\n"
     ]
    }
   ],
   "source": [
    "x = np.array([4.6, 3, 7, 4.2, 5.0], dtype=float)\n",
    "print (np.sort(x))\n",
    "print (x.mean())\n",
    "print (np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Control:** mean = 4, median = 4.2 \n",
    "**3.2 -> 1:** mean = 3.56, median = 4.2 \n",
    "**3.2 -> 5:** mean = 4.36, median = 4.6  \n",
    "**3.2 -> 6:** mean = 4.56, median = 4.6  \n",
    "**3.2 -> 7:** mean = 4.76, median = 4.6 \n",
    "**3.2 -> 10:** mean = 5.36, median = 4.6  \n",
    "**3.2 -> 20:** mean = 7.36, median = 4.6  \n",
    "**3.2 -> 50:** mean = 13.36, median = 4.6  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results for Median:** If y < 4.2, the median will be 4.2 always  \n",
    "If 4.2 < y < 4.6 then the median will be y  \n",
    "If y > 4.2 then the meidan will always be 4.6  \n",
    "**Results for Mean:** As $y \\rightarrow \\infty$, the mean increases proportionally to the dataset. Doesnt seem like anything out of the ordinary. Only what you would expect when changing a number in an array. The bigger the number, the more skewed the mean will be towards the outlier. You can see from above, that around 3.2->7 that the mean is still near the median, and the mean may not fully explain that there is an outlier or if most of the numbers are just around the median, 4.6. As the mean gets higher, its easier to tell that there is an outlier that is akewing the means towards it, as in 3.2->50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: We replace a number of elements by some real number $y$. How many elements do we need to replace so that the sample median of the new dataset goes to infinity as $y \\rightarrow \\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Initial thoughts:** We would have to replace a majority of the numbers to make the $median \\rightarrow \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Control:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   3.2  4.2  4.6  5. ]\n",
      "4.2\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3.2, 4.2, 4.6, 3, 5], dtype=float)\n",
    "print (np.sort(x))\n",
    "print (np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace the minumum number in array to be larger than the median:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   3.2  4.2  4.6  5. ]\n",
      "4.2\n",
      "[ 3.2  4.2  4.6  4.7  5. ]\n",
      "4.6\n",
      "[ 4.2  4.6  4.7  5.   5.1]\n",
      "4.7\n",
      "[ 4.6  4.7  5.   5.1  5.2]\n",
      "5.0\n",
      "[ 4.7  5.   5.1  5.2  5.5]\n",
      "5.1\n",
      "[ 5.   5.1  5.2  5.5  5.6]\n",
      "5.2\n",
      "[ 5.1  5.2  5.5  5.6  5.7]\n",
      "5.5\n",
      "[ 5.2  5.5  5.6  5.7  6. ]\n",
      "5.6\n",
      "[ 5.5  5.6  5.7  6.   6.1]\n",
      "5.7\n"
     ]
    }
   ],
   "source": [
    "while (np.median(x) < 6):\n",
    "    print (np.sort(x))\n",
    "    print (np.median(x))\n",
    "    x[np.argmin(x)] = np.median(x) + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would actually only have to change 1 number at the minimum to make $median \\rightarrow \\infty$ true. Change the minimum number each time to be greater than the current median works as a solution. You can also change it to the max number each time, either works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Suppose we have another data set of size $n$. How many elements do we need to replace by some real number $y$, so that the sample mean of the new dataset goes to infinity as $y \\rightarrow \\infty$? And how many elements do we need to replace, so that the sample median of the new dataset goes to infinity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To make $mean \\rightarrow \\infty$ you would (like above) change only one number to be above the max number or the median. \n",
    "\n",
    "To make $median \\rightarrow \\infty$ you would still only change the minimum number to be above the median. Or more general, change any number below the median to above the median.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 \n",
    "***\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2\n",
    "$$\n",
    "\n",
    "where here the subscript $n$'s indicate the number of observations in the sample. Notice that a natural computation of the variance requires two passes over the data: one to compute the mean, and a second to subtract the mean from each observation and compute the sum of squares. It is often useful to be able to compute the variance in a single pass, inspecting each value $x_k$ only once; for example, when the data are being collected without enough storage to keep all the values, or when costs of memory access dominate those of computation. In this problem you will explore two methods for such an _online_ computation of the mean and variance.  \n",
    "\n",
    "**Part A**: Show algebraically that the following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the summation rule, we are able to break down these sums a bit eaiser:\n",
    "\n",
    "$$\\sum_{k=1}^{n} x_k= \\frac{n(n+1)}{2}$$ \n",
    " \n",
    "Using the above summation form, we able to derive these: \n",
    " \n",
    "$$x_k=x_n=n$$\n",
    "\n",
    "\n",
    "$$\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k=\\frac{1}{n}\\frac{n(n+1)}{2}=\\frac{n+1}{2}$$\n",
    "\n",
    "$$\\bar{x}_{n-1} = \\frac{1}{n-1}\\sum_{k=1}^{n-1} x_k=\\frac{1}{n-1}\\frac{n-1(n-1+1)}{2}=\\frac{n}{2}$$\n",
    "\n",
    "Plugging in all of these numbers into Part A:\n",
    "\n",
    "$$\\bar{x}_n=\\frac{n+1}{2}$$\n",
    "\n",
    "$$\\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}=\\frac{n}{2}+\\frac{n-\\frac{n}{2}}{n}$$\n",
    "\n",
    "$$\\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}=\\frac{n}{2}+\\frac{n-\\frac{n}{2}}{n}$$\n",
    "\n",
    "$$\\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}=\\frac{n}{2}+\\frac{1}{2}$$\n",
    "\n",
    "$$\\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}=\\frac{n+1}{2}$$\n",
    "\n",
    "As you can see, in the end everything is equal to eachother!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< Updated upstream
    "**Part B (Extra Credit)**: Show algebraically that the following relation holds between the variance of the first $n-1$ observations and the variance of all $n$ observations: \n",
=======
    "**Part B (EC)**: Show algebraically that the following relation holds between the variance of the first $n-1$ observations and the variance of all $n$ observations: \n",
>>>>>>> Stashed changes
    "\n",
    "$$\n",
    "s^2_n = \\frac{(n-2)}{(n-1)}s^2_{n-1} + \\frac{(x_n - \\bar{x}_{n-1})^2}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: It turns out that in some scenarios the variance calculation in **Part B** can suffer from numerical instability (that is, due to round-off errors and finite precision arithmetic, the algorithm can return garbage).  A better method is to update the sum of squares term incrementally and then divide by $n-1$ at the end.  Define the sum of squares with $n$ observations as $\n",
    "M_n = \\sum_{k=1}^n (x_k - \\bar{x}_n)^2$. We can then compute the sample variance as $s_n^2 = M_n/(n-1)$.\n",
    "\n",
    "Show algebraically that the following relation holds between the sum of squares with $n-1$ observations and the sum of squares with all $n$ observations: \n",
    "\n",
    "$$\n",
    "M_n = M_{n-1} + (x_n - \\bar{x}_{n-1})(x_n - \\bar{x}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informative But Not Required**: Write a Python function that implements the online variance computation in **Part C** and  requires only one pass over the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by class warfare; others claim it was characterized by male chivalry.  We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the titanic data in titanic_data.csv and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival of passengers (**Survived**), and gender (**Sex**), among others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path = 'titanic_data.csv'\n",
    "dfT= pd.read_csv(local_path)\n",
    "dfT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Explain in words what patterns you might see in the data if there were male chivalry in the final hours aboard the Titanic?  What patterns might you see if there were class warfare in the final hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Determine the fraction of survivors from each passenger class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the fraction of survivors according to class and gender.  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Make any necessary graphical summaries to justify your conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Were the median and mean ages for females who survived higher or lower than for females who did not survive?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "***\n",
    "Access the data from url https://www.stat.berkeley.edu/~statlabs/data/babies.data and store the information in a Pandas DataFrame.  A description of the variables can be found at https://www.stat.berkeley.edu/~statlabs/labs.html.  These data are a subset from a much larger study dealing with child health and development. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part A**: Create a clean data set that removes subjects if any observations on the subject are unknown.  Note that that collectors of the data set used values like $9$, $99$, $999$, to denote unknown values.  You can look at the documentation linked in the problem description to determine which unknown-value marker was used for each characteristic.  Store the modified data set in a Pandas DataFrame called dfBabies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use the information in dfBabies to create a density histogram of the birth weights of babies whose mothers have never smoked (smoke=0) and another histogram placed directly below the first in the same graphics device for the birth weights of babies whose mothers currently smoke (smoke=1).  Make the range of the horizontal axis $30$ to $180$ (ounces) for both histograms.  Make sure to give each subplot titles and label axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Based on the histograms in **Part B**, characterize the distribution of baby birth weights for both non-smoking and smoking mothers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: What are the mean and median weight difference between babies of smokers and non-smokers?  Can you think of any reason not to use the mean as a measure of center to compare birth weights for this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Create side-by-side box-and-whisker plots to compare the birth weights of babies whose mothers never smoked and those who currently smoke.  Use the box-and-whisker plot conventions discussed in lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Using the box-and-whisker plots from **Part E** comment on the distributions of body weights of babies within each smoking / non-smoking groups as well as the comparison of the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Cleaning Election Results Data  \n",
    "***\n",
    "\n",
    "The file 2014\\_election\\_results.csv contains data from congressional district races during the 2014 midterm elections.  The problem is that the data is **extremely dirty**.  Your goal in the problem will be to use Pandas to clean the election result data and then, if possible, determine the names of the winners in each congressional district as well as the vote percentage margin that they won by.  Remember that data cleaning and wrangling is a messy business.  Don't be afraid to roll your sleeves up and get hacky!   \n",
    "\n",
    "**Part A**: Complete the clean_election_data( ) function to return a clean DataFrame that accomplishes the following: \n",
    "\n",
    "- remove rows in the DataFrame that are missing values in columns **STATE**, **D**, and/or **GENERAL PERCENT**\n",
    "\n",
    "<p> </p> \n",
    "\n",
    "- replace unknown names in **CANDIDATE NAME** with:  \n",
    "    - the value from **CANDIDATE NAME (Last)**, if available\n",
    "    - the string \"UNKNOWN\" if impossible to determine the full or last name \n",
    "    - **Note**: besides \"NaN\", data collectors appear to have used the string \"Scattered\" to indicate missing names as well\n",
    "<p> </p> \n",
    "- convert the strings in **GENERAL PERCENT** to values of type float between $0$ and $100$ \n",
    "<p> </p> \n",
    "- restrict the DataFrame to only the columns **STATE**, **D**, **CANDIDATE NAME**, **GENERAL PERCENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_election_data():\n",
    "    '''\n",
    "    Function to clean election data \n",
    "    '''\n",
    "    \n",
    "    # read in dirty data \n",
    "    df = pd.read_csv(\"2014_election_results.csv\")\n",
    "    \n",
    "    return dfClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Complete the function winners_and_margins( ) that takes in your clean DataFrame from **Part A** and returns a DataFrame with one row per state-district pair and with columns **STATE**, **D**, **WINNER**, and **MARGIN** where\n",
    "\n",
    "- **STATE** and **D** are as defined in the original DataFrame \n",
    "<p> </p> \n",
    "- **WINNER** is the name of the candidate that had the largest general vote percentage (which may possibly be \"UNKNOWN\")\n",
    "<p> </p> \n",
    "- **MARGIN** is the difference between the winning general vote percentage and the second highest vote percentage.  If there is only one candidate in a particular district you should list the general vote percentage obtained by the sole candidate. \n",
    "\n",
    "<p> </p> \n",
    "\n",
    "Finally, your DataFrame should be **sorted from most contentious races to least contentious** (i.e. from smallest winning margin to the largest). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winners_and_margins(df):\n",
    "    \n",
    "    return dfWinners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Problem\n",
    "***\n",
    "\n",
    "In every homework assignment we'll give you a Challenge Problem.  Challenge Problems never need to be turned in (and in fact, will not be graded) but we encourage you to give them a shot (after completing the required homework problems) and discuss them with your classmates and your instructors.  \n",
    "\n",
    "In the 1954 book _How to Lie with Statistics_, authors Darrell Huff and Irving Geis describe some common ways that people concoct misleading graphics.  An excerpt from these chapters can be found [here](https://piazza.com/class_profile/get_resource/j6pfvv6b9ze4gi/j771gy7fdpe3e7).  \n",
    "\n",
    "Your job is to go out onto the web and find some data that you find interesting.  Then create both a misleading and a non-misleading version of a graphical summary for the data. **If you come up with something that you're proud of then please post it to Piazza!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
